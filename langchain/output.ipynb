{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fd20ce-5722-42bb-aca6-f6944f9a6572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/miniconda3/envs/langchain/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser, JsonOutputParser, XMLOutputParser, BaseOutputParser\n",
    "from langchain.output_parsers import RetryOutputParser, OutputFixingParser\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "from typing import List\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "# base_url = \"https://api.deepseek.com/\"\n",
    "\n",
    "# model=\"deepseek-chat\"\n",
    "# llm = ChatOpenAI(model=model, temperature=0, api_key=api_key, base_url=base_url)\n",
    "\n",
    "base_url=\"https://ark.cn-beijing.volces.com/api/v3\"\n",
    "\n",
    "model=\"doubao-1.5-pro-32k-250115\"\n",
    "llm = ChatOpenAI(model=model, temperature=0, api_key=api_key, base_url=base_url)\n",
    "\n",
    "# base_url=\"http://localhost:11434\"\n",
    "# model=\"deepseek-r1\"\n",
    "# llm = ChatOllama(model=model, temperature=0, base_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "490cb90e-b206-48f2-bf14-ddb906725a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='用户想了解北京市当前的天气，调用 get_weather 函数获取相关信息。', additional_kwargs={'tool_calls': [{'id': 'call_8qhubr3mrq2ipb1h6kygqrdd', 'function': {'arguments': ' {\"location\": \"北京市\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 62, 'total_tokens': 119, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'doubao-1-5-pro-32k-250115', 'system_fingerprint': None, 'id': '021759885048762c6f82c6173ae2988dd3f2bc3d220408fcfed4d', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--75ed6272-72cd-4683-a41a-8d9cd6f724e1-0', tool_calls=[{'name': 'get_weather', 'args': {'location': '北京市'}, 'id': 'call_8qhubr3mrq2ipb1h6kygqrdd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 62, 'output_tokens': 57, 'total_tokens': 119, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"根据location地名返回当地实时天气.\"\"\"\n",
    "    return \"天气晴朗22度\"\n",
    "llm_with_tools = llm.bind_tools([get_weather])\n",
    "chain = llm_with_tools #| StrOutputParser()\n",
    "response = chain.invoke(\"北京市当前的天气如何\")\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99671549-5c76-449e-9994-7baa4a1f23d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回答用户的查询.\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"setup\": {\"description\": \"笑话中的铺垫问题，必须以?结尾\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"笑话中回答铺垫问题的部分，通常以抖包袱方式回单铺垫问题，例如谐音，会错意等\", \"title\": \"Punchline\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
      "```\n",
      "给我讲一个笑话\n",
      "\n",
      "{'setup': '为什么许仙给白娘子买了顶帽子，白娘子觉得头很重? ', 'punchline': '因为那是顶鸭舌（压蛇）帽。'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Joke(setup='为什么许仙给白娘子买了顶帽子，白娘子觉得头很重? ', punchline='因为那是顶鸭舌（压蛇）帽。')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"笑话中的铺垫问题，必须以?结尾\")  #description中的内容通过get_format_instructions()转换成相应的提示词\n",
    "    punchline: str = Field(description=\"笑话中回答铺垫问题的部分，通常以抖包袱方式回单铺垫问题，例如谐音，会错意等\")\n",
    "    \n",
    "    @model_validator(mode=\"before\")\n",
    "    @classmethod\n",
    "    def question_ends_with_question_mark(cls, values: dict) -> dict:\n",
    "        print(values)\n",
    "        setup = values.get(\"setup\")\n",
    "        if setup and setup.strip()[-1] != \"？\" and setup.strip()[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return values\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"回答用户的查询.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "print(prompt.format(query=\"给我讲一个笑话\"))\n",
    "chain = prompt | llm | parser\n",
    "chain.invoke({\"query\": \"给我讲一个笑话\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56db5a89-7ce0-4d0e-afdc-ab957e07197a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回答用户的查询.\n",
      "Return a JSON object.\n",
      "给我讲一个笑话\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'joke': '小蚂蚁迷路找不到蚁窝，可着急了，恰好看到它的朋友经过，于是冲过去大喊一声：“哥们儿！你…你都如何回蚁窝（回忆我）？”那朋友一愣，然后反问道：“带…带…带着笑或是很沉默？”'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = JsonOutputParser()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"回答用户的查询.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "print(prompt.format(query=\"给我讲一个笑话\"))\n",
    "chain = prompt | llm | parser\n",
    "chain.invoke({\"query\": \"给我讲一个笑话\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1fe5115-1e4b-474e-987d-5c2d20ea3f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回答用户的查询.\n",
      "The output should be formatted as a XML file.\n",
      "1. Output should conform to the tags below.\n",
      "2. If tags are not given, make them on your own.\n",
      "3. Remember to always open and close all the tags.\n",
      "\n",
      "As an example, for the tags [\"foo\", \"bar\", \"baz\"]:\n",
      "1. String \"<foo>\n",
      "   <bar>\n",
      "      <baz></baz>\n",
      "   </bar>\n",
      "</foo>\" is a well-formatted instance of the schema.\n",
      "2. String \"<foo>\n",
      "   <bar>\n",
      "   </foo>\" is a badly-formatted instance.\n",
      "3. String \"<foo>\n",
      "   <tag>\n",
      "   </tag>\n",
      "</foo>\" is a badly-formatted instance.\n",
      "\n",
      "Here are the output tags:\n",
      "```\n",
      "['movies', 'actor', 'film', 'name', 'genre']\n",
      "```\n",
      "Generate the shortened filmography for Tom Hanks.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'movies': [{'actor': [{'name': 'Tom Hanks'},\n",
       "    {'film': [{'name': 'Forrest Gump'}, {'genre': 'Drama'}]},\n",
       "    {'film': [{'name': 'Apollo 13'}, {'genre': 'Drama'}]},\n",
       "    {'film': [{'name': 'The Green Mile'}, {'genre': 'Drama'}]}]}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = XMLOutputParser(tags=[\"movies\", \"actor\", \"film\", \"name\", \"genre\"])\n",
    "prompt = PromptTemplate(\n",
    "    template=\"回答用户的查询.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "actor_query = \"Generate the shortened filmography for Tom Hanks.\"\n",
    "print(prompt.format(query=actor_query))\n",
    "chain = prompt | llm | parser\n",
    "chain.invoke({\"query\": actor_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "476019c3-6a06-4855-a1a1-2ed5d37ed70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse Action from completion {\"action\": \"search\"}. Got: 1 validation error for Action\n",
      "action_input\n",
      "  Field required [type=missing, input_value={'action': 'search'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Action(action='query_weather', action_input='今天北京的天气')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Action(BaseModel):\n",
    "    action: str = Field(description=\"action to take\")  #description中的内容通过get_format_instructions()转换成相应的提示词\n",
    "    action_input: str = Field(description=\"input to the action\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Action)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "prompt_value = prompt.format_prompt(query=\"今天北京天气如何?\")\n",
    "bad_response = '{\"action\": \"search\"}' # 假设得到一个错误回答，不符合parser字段要求\n",
    "try:\n",
    "    parser.parse(bad_response)\n",
    "except OutputParserException as e:\n",
    "    print(e)\n",
    "retry_parser = RetryOutputParser.from_llm(parser=parser, llm=llm)\n",
    "retry_parser.parse_with_prompt(bad_response, prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d8163ec-6d72-4442-9647-5096a62190c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid json output: {'name': 'Tom Hanks', 'film_names: ['Gorrest Gump']}\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Actor(name='Tom Hanks', film_names=['Forrest Gump'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Actor(BaseModel):\n",
    "    name: str = Field(description=\"name of an actor\")\n",
    "    film_names: List[str] = Field(description=\"list of names of films they starred in\")\n",
    "\n",
    "actor_query = \"Generate the shortened filmography for Tom Hanks.\"\n",
    "parser = PydanticOutputParser(pydantic_object=Actor)\n",
    "misformatted = \"{'name': 'Tom Hanks', 'film_names: ['Gorrest Gump']}\" # 错误的json格式，使用了单引号，而不是双引号\n",
    "try:\n",
    "    parser.parse(misformatted)\n",
    "except OutputParserException as e:\n",
    "    print(e)\n",
    "fixing_parser = OutputFixingParser.from_llm(parser=parser, llm=llm)\n",
    "fixing_parser.parse(misformatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94f29195-d74e-4b9a-8886-76f9f7ddede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BooleanOutputParser expected output value to either be YES or NO (case-insensitive). Received ye.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    }
   ],
   "source": [
    "class BooleanOutputParser(BaseOutputParser[bool]):\n",
    "    \"\"\"Custom boolean parser.\"\"\"\n",
    "    true_val: str = \"YES\"\n",
    "    false_val: str = \"NO\"\n",
    "\n",
    "    def parse(self, text: str) -> bool:\n",
    "        cleaned_text = text.strip().upper()\n",
    "        if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):\n",
    "            raise OutputParserException(\n",
    "                f\"BooleanOutputParser expected output value to either be \"\n",
    "                f\"{self.true_val} or {self.false_val} (case-insensitive). \"\n",
    "                f\"Received {text}.\"\n",
    "            )\n",
    "        return cleaned_text == self.true_val.upper()\n",
    "\n",
    "    @property\n",
    "    def __type(self) -> str:\n",
    "        return \"boolean_output_parser\"\n",
    "\n",
    "parser = BooleanOutputParser()\n",
    "try:\n",
    "    parser.invoke(\"ye\")\n",
    "except OutputParserException as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
